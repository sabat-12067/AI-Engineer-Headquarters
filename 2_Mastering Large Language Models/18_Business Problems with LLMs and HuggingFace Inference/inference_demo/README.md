# LLM for Inference using HuggingFace

1. create and account on huggingface
2. go to setting and access tokens
3. create API token and copy paste it in the .env file of your project
4. install some libraries - huggingface_hub and python-dotenv
5. generate FAQs


Play with examples
1 - generating FAQs
2 - article summarizer
3 - creative writing generator


Tasks
- analyze a business use cases for LLM in your industry
https://cloud.google.com/transform/101-real-world-generative-ai-use-cases-from-industry-leaders

- design a workflow for an LLM based application (use excalidraw for the diagram)
- build a text generation App using huggingface API and Flask
