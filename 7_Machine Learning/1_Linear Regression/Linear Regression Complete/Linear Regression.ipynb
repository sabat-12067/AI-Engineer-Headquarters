{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Linear Regression\n",
    "Simple linear regression is a statistical technique used for finding the existence of an association \n",
    "relationship between a dependent variable (aka response variable or outcome variable) and an independent\n",
    "variable (aka explanatory variable, predictor variable or feature).\n",
    "<br>\n",
    "<br>\n",
    "Regression is one of the most popular supervised learning algorithms in predictive analytics. A regression model requires the knowledge of both the outcome and the feature variables in the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. A hospital may be interested in finding how the total cost of a patient for a treatment varies with the body weight of the patient.\n",
    "2. Insurance companies would like to understand the association between healthcare costs and ageing.\n",
    "3. An organization may be interested in finding the relationship between revenue generated from a product and features such as the price, money spent on promotion, competitors’ price, and promotion expenses.\n",
    "4. Restaurants would like to know the relationship between the customer waiting time after placing the order and the revenue.\n",
    "5. E-commerce companies such as Amazon, BigBasket, and Flipkart would like to understand the relationship between revenue and features such as <br>\n",
    "(a) Number of customer visits to their portal.<br>\n",
    "(b) Number of clicks on products.<br>\n",
    "(c) Number of items on sale.<br>\n",
    "(d) Average discount percentage.<br>\n",
    "6. Banks and other financial institutions would like to understand the impact of variables such as unemployment rate, marital status, balance in the bank account, rain fall, etc. on the percentage of non-performing assets (NPA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEPS IN BUILDING A REGRESSION MODEL\n",
    "In this section, we will explain the steps used in building a regression model. Building a regression\n",
    "model is an iterative process and several iterations may be required before finalizing the appropriate\n",
    "model.\n",
    "#### STEP 1: Collect/Extract Data\n",
    "The first step in building a regression model is to collect or extract data on the dependent (outcome) vari-\n",
    "able and independent (feature) variables from different data sources. Data collection in many cases can\n",
    "be time-consuming and expensive, even when the organization has well-designed enterprise resource\n",
    "planning (ERP) system.\n",
    "#### STEP 2: Pre-Process the Data\n",
    "Before the model is built, it is essential to ensure the quality of the data for issues such as reliability, com-\n",
    "pleteness, usefulness, accuracy, missing data, and outliers.\n",
    "1. Data imputation techniques may be used to deal with missing data. Use of descriptive statistics and visualization (such as box plot and scatter plot) may be used to identify the existence of outliers and variability in the dataset.\n",
    "2. Many new variables (such as the ratio of variables or product of variables) can be derived (aka feature engineering) and also used in model building.\n",
    "3. Categorical data has must be pre-processed using dummy variables (part of feature engineering) before it is used in the regression model.\n",
    "\n",
    "#### STEP 3: Dividing Data into Training and Validation Datasets\n",
    "In this stage the data is divided into two subsets (sometimes more than two subsets): training dataset\n",
    "and validation or test dataset. The proportion of training dataset is usually between 70% and 80% of the\n",
    "data and the remaining data is treated as the validation data. The subsets may be created using random/­\n",
    "stratified sampling procedure. This is an important step to measure the performance of the model using\n",
    "dataset not used in model building. It is also essential to check for any overfitting of the model. In many\n",
    "cases, multiple training and multiple test data are used (called cross-validation).\n",
    "\n",
    "#### STEP 4: Perform Descriptive Analytics or Data Exploration\n",
    "It is always a good practice to perform descriptive analytics before moving to building a predictive ana-\n",
    "lytics model. Descriptive statistics will help us to understand the variability in the model and visualiza-\n",
    "tion of the data through, say, a box plot which will show if there are any outliers in the data. Another\n",
    "visualization technique, the scatter plot, may also reveal if there is any obvious relationship between the\n",
    "two variables under consideration. Scatter plot is useful to describe the functional relationship between\n",
    "the dependent or outcome variable and features.\n",
    "#### STEP 5: Build the Model\n",
    "The model is built using the training dataset to estimate the regression parameters. The method of\n",
    "Ordinary Least Squares (OLS) is used to estimate the regression parameters.\n",
    "#### STEP 6: Perform Model Diagnostics\n",
    "Regression is often misused since many times the modeler fails to perform necessary diagnostics tests\n",
    "before applying the model. Before it can be applied, it is necessary that the model created is validated\n",
    "for all model assumptions including the definition of the function form. If the model assumptions are\n",
    "violated, then the modeler must use remedial measure.\n",
    "#### STEP 7: Validate the Model and Measure Model Accuracy\n",
    "A major concern in analytics is over-fitting, that is, the model may perform very well on the training\n",
    "dataset, but may perform badly in validation dataset. It is important to ensure that the model perfor-\n",
    "mance is consistent on the validation dataset as is in the training dataset. In fact, the model may be cross-\n",
    "validated using multiple training and test datasets.\n",
    "#### STEP 8: Decide on Model Deployment\n",
    "The final step in the regression model is to develop a deployment strategy in the form of actionable items\n",
    "and business rules that can be used by the organization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILDING SIMPLE LINEAR REGRESSION MODEL\n",
    "Simple Linear Regression (SLR) is a statistical model in which there is only one independent vari-\n",
    "able (or feature) and the functional relationship between the outcome variable and the regression\n",
    "coefficient is linear. Linear regression implies that the mathematical function is linear with respect to\n",
    "regression parameters.\n",
    "One of the functional forms of SLR is as follows:\n",
    "<img src=\"q.png\" />\n",
    "\n",
    "For a dataset with n observations (X i , Y i ), where i = 1, 2, ..., n, the above functional form can be written\n",
    "as follows:\n",
    "<img src=\"w.png\" />\n",
    "\n",
    "where Y i is the value of ith observation of the dependent variable (outcome variable) in the sample, X i is\n",
    "the value of ith observation of the independent variable or feature in the sample, e i is the random error\n",
    "(also known as residuals) in predicting the value of Y i , b 0 and b 1 are the regression parameters (or regres-\n",
    "sion coefficients or feature weights).\n",
    "\n",
    "The regression relationship stated is a statistical relationship, and so is not exact, unlike\n",
    "a mathematical relationship, and thus the error terms e i . It can be written as\n",
    "<img src=\"e.png\" />\n",
    "The regression parameters b 0 and b 1 are estimated by minimizing the sum of squared errors (SSE).\n",
    "n n\n",
    "i = 1 i = 1\n",
    "<img src=\"r.png\" />\n",
    "The estimated values of regression parameters are given by taking partial derivative of SSE with respect\n",
    "to b 0 and b 1 and solving the resulting equations for the regression parameters. The estimated parameter\n",
    "values are given by\n",
    "<img src=\"t.png\" />\n",
    "\n",
    " are the estimated values of the regression parameters b and b . The above proce-\n",
    "where b\n",
    "0\n",
    "1\n",
    "0\n",
    "1\n",
    "dure is known as method of ordinary least square (OLS). The estimate using OLS gives the best linear\n",
    "unbiased estimates (BLUE) of regression parameters.\n",
    "\n",
    "Assumptions of the Linear Regression Model\n",
    "1. The errors or residuals e i are assumed to follow a normal distribution with expected value of error E(e i ) = 0.\n",
    "2. The variance of error, VAR(e i ), is constant for various values of independent variable X. This is known as homoscedasticity. When the variance is not constant, it is called heter­oscedasticity.\n",
    "3. The error and independent variable are uncorrelated.\n",
    "4. The functional relationship between the outcome variable and feature is correctly defined.\n",
    "\n",
    "Properties of Simple Linear Regression\n",
    "1. The mean value of Y i for given X i , E ( Y i | X ) = b\n",
    "\n",
    "2. Y i follows a normal distribution with mean b\n",
    "\n",
    "Let us consider an example of predicting MBA Salary (outcome variable) from marks in GMAT marks.\n",
    "(feature)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Field Description age age - in years<br>\n",
    "sex 1=Male; 2=Female<br>\n",
    "gmat_tot total GMAT score<br>\n",
    "gmat_qpc quantitative GMAT percentile<br>\n",
    "gmat_vpc verbal GMAT percentile<br>\n",
    "qmat_tpc overall GMAT percentile<br>\n",
    "s_avg spring MBA average<br>\n",
    "f_avg fall MBA average<br>\n",
    "quarter quartile ranking (1st is top, 4th is bottom)<br>\n",
    "work_yrs years of work experience<br>\n",
    "frstlang first language (1=English; 2=other)<br>\n",
    "salary starting salary<br>\n",
    "satis degree of satisfaction with MBA program (1= low, 7 = high satisfaction)<br>\n",
    "<br>\n",
    "Missing salary and data are coded as follows:<br>\n",
    "998 = did not answer the survey<br>\n",
    "999 = answered the survey but did not disclose salary data<br>\n",
    "Size of data set: 274 records<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Feature Set X and Outcome Variable Y\n",
    "The statsmodel library is used in Python for building statistical models. OLS API available in statsmodel.api\n",
    "is used for estimation of parameters for simple linear regression model. \n",
    "\n",
    "The OLS() model takes two parameters Y and X. In this example, Percentage in Grade 10 will be X and Salary will be Y. \n",
    "\n",
    "OLS API available in statsmodel.api estimates only the coefficient of X parameter. To estimate regression coefficient b 0 , a constant term of 1 needs to be added as a separate column. \n",
    "\n",
    "As the value of the columns remains\n",
    "same across all samples, the parameter estimated for this feature or column will be the intercept term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Dataset into Training and Validation Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the Model\n",
    "We will fit the model using OLS method and pass train_y and train_X as parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mba_salary_lm = sm.OLS(train_y, train_X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fit() method on OLS() estimates the parameters and returns model information to the variable mba_\n",
    "salary_lm, which contains the model parameters, accuracy measures, and residual values among other details.\n",
    "### Printing Estimated Parameters and Interpreting Them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The estimated (predicted) model can be written as\n",
    "MBA Salary = 57452.82 + (-31.088619) * (gmat_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL DIAGNOSTICS\n",
    "It is important to validate the regression model to ensure its validity and goodness of fit before it\n",
    "can be used for practical applications. The following measures are used to validate the simple linear\n",
    "regression models:\n",
    "1. Co-efficient of determination (R-squared).\n",
    "2. Hypothesis test for the regression coefficient.\n",
    "3. Analysis of variance for overall model validity (important for multiple linear regression).\n",
    "4. Residual analysis to validate the regression model assumptions.\n",
    "5. Outlier analysis, since the presence of outliers can significantly impact the regression parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-efficient of Determination (R-Squared or R 2 )\n",
    "The primary objective of regression is to explain the variation in Y using the knowledge of X. The\n",
    "co-efficient of determination (R-squared or R 2 ) measures the percentage of variation in Y explained by\n",
    "the model (b 0 + b 1 X). The simple linear regression model can be broken into\n",
    "1. Variation in outcome variable explained by the model.\n",
    "2. Unexplained variation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"one.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be proven mathematically that <br>\n",
    "<img src = \"two.png\" />\n",
    "SST is the sum of squares of total variation,SSR is the sum of squares of explained variation due to the regression model, and SSE is the sum of squares of unexplained variation (error).\n",
    "\n",
    "\n",
    "The co-efficient\n",
    "of determination (R-squared) is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"three.png\" />\n",
    "\n",
    "The co-efficient of determination (R-squared) has the following properties:\n",
    "1. The value of R-squared lies between 0 and 1.\n",
    "2. Mathematically, R-squared (R 2 ) is square of correlation coefficient (R 2 = r 2 ), where r is the Pearson correlation co-efficient.\n",
    "3. Higher R-squared indicates better fit; however, one should be careful about the false relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Test for the Regression Co-eff icient\n",
    "The regression co-efficient (b 1 ) captures the existence of a linear relationship between the outcome vari-\n",
    "able and the feature. If b 1 = 0, we can conclude that there is no statistically significant linear relationship\n",
    "between the two variables. \n",
    "\n",
    "It can be proved that the sampling distribution of b 1 is a t-distribution. \n",
    "\n",
    "The null and alternative hypotheses are\n",
    "\n",
    "<img src = \"four.png\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Variance (ANOVA) in Regression Analysis\n",
    "We can check the overall validity of the regression model using ANOVA in the case of multiple linear\n",
    "regression model with k features. The null and alternative hypotheses are given by\n",
    "<img src = \"five.png\" />\n",
    "H A : Not all regression coefficients are zero\n",
    "The corresponding F-statistic is given by\n",
    "\n",
    "<img src = \"six.png\" />\n",
    "\n",
    "\n",
    "\n",
    "where MSR (= SSR/k) and MSE [= SSE/(n − k − 1)] are mean squared regression and mean squared error,\n",
    "respectively. F-test is used for checking whether the overall regression model is statistically significant or not.\n",
    "\n",
    "## Regression Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From the summary output\n",
    "1. The model R-squared value is 0.001, that is, the model explains 0.1% of the variation in salary.\n",
    "2. The p-value for the t-test is 0.5935 which indicates that there is not a statistically significant relationship (at significance value a = 0.05) between the feature, gmat_tot, and salary.\n",
    "\n",
    "Also, the probability value of F-statistic of the model is 0.594 which indicates that the overall model is not statistically significant. Note that, in a simple linear regression, the p-value for t-test and F-test will be the same since the null hypothesis is the same. (Also F = t 2 in the case of SLR.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Residual Analysis\n",
    "Residuals or errors are the difference between the actual value of the outcome variable and the predicted value ( Y - Y hat ) . Residual (error) analysis is important to check whether the assumptions of regression models have been satisfied. It is performed to check the following:\n",
    "1. The residuals are normally distributed.\n",
    "2. Variance of residual is constant (homoscedasticity).\n",
    "3. The functional form of regression is correctly specified.\n",
    "4. There are no outliers.\n",
    "\n",
    "#### Check for Normal Distribution of Residual\n",
    "The normality of residuals can be checked using the probability−probability plot (P-P plot). P-P plot\n",
    "compares the cumulative distribution function of two probability distributions against each other. In\n",
    "the current context, we use the P-P plot to check whether the distribution of the residuals matches with\n",
    "that of a normal distribution. In Python, ProbPlot() method on statsmodel draws the P-P plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The diagonal line is the cumulative distribution of a normal distribution, whereas the dots\n",
    "represent the cumulative distribution of the residuals. \n",
    "\n",
    "Since the dots are close to the diagonal line, we can\n",
    "conclude that the residuals follow an approximate normal distribution (we need only an approximate\n",
    "normal distribution)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test of Homoscedasticity\n",
    "An important assumption of the regression model is that the residuals have constant variance\n",
    "(homoscedasticity) across different values of the predicted value (Y). \n",
    "\n",
    "The homoscedasticity can be\n",
    "observed by drawing a residual plot, which is a plot between standardized residual value and standardized predicted value. If there is heteroscedasticity (non-constant variance of residuals), then a\n",
    "funnel type shape in the residual plot can be expected. \n",
    "\n",
    "A non-constant variance of the residuals is\n",
    "known as heteroscedasticity.\n",
    "\n",
    "\n",
    "The following custom method get_standardized_values() creates the standardized values of\n",
    "a series of values (variable). It subtracts values from mean and divides by standard deviation of\n",
    "the variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "observed that the residuals are random and have funnel shape, which means\n",
    "the residuals have non constant variance (heteroscedasticity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier Analysis\n",
    "Outliers are observations whose values show a large deviation from the mean value. Presence of an\n",
    "outlier can have a significant influence on the values of regression coefficients. Thus, it is important to\n",
    "identify the existence of outliers in the data.\n",
    "The following distance measures are useful in identifying influential observations:\n",
    "1. Z-Score\n",
    "2. Mahalanobis Distance\n",
    "3. Cook’s Distance\n",
    "4. Leverage Values\n",
    "\n",
    "### Z-Score\n",
    "Z-score is the standardized distance of an observation from its mean value. For the predicted value of the\n",
    "dependent variable Y, the Z-score is given by\n",
    "\n",
    "<img src = \"seven.png\" />\n",
    "\n",
    "where Y i is the predicted value of Y for ith observation, Y is the mean or expected value of Y, s Y is the\n",
    "variance of Y.\n",
    "Any observation with a Z-score of more than 3 may be flagged as an outlier. The Z-score in the data\n",
    "can be obtained using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are one observation that are outliers as per the Z-score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cook’s Distance\n",
    "Cook’s distance measures how much the predicted value of the dependent variable changes for all the\n",
    "observations in the sample when a particular observation is excluded from the sample for the estimation\n",
    "of regression parameters.\n",
    "\n",
    "\n",
    "A Cook’s distance value of more than 1 indicates highly influential observation. Python code for\n",
    "calculating Cook’s distance is provided below. In this get_influence() returns the influence of observations\n",
    "in the model and cook_distance variable provides Cook’s distance measures. \n",
    "\n",
    "Then the distances can be\n",
    "plotted against the observation index to find out which observations are influential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "it can be observed that none of the observations’ Cook’s distance exceed 1 and hence\n",
    "none of them are outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leverage Values\n",
    "Leverage value of an observation measures the influence of that observation on the overall fit of the\n",
    "regression function and is related to the Mahalanobis distance. \n",
    "\n",
    "Leverage value of more than 3(k + 1)/n\n",
    "is treated as highly influential observation, where k is the number of features in the model and n is the\n",
    "sample size.\n",
    "statsmodels.graphics.regressionplots module provides influence_plot() which draws a plot between\n",
    "standardized residuals and leverage value. \n",
    "\n",
    "Mostly, the observations with high leverage value (as men-\n",
    "tioned above) and high residuals [more than value 3(k + 1)/n] can be removed from the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the size of the circle is proportional to the product of residual and leverage value. The\n",
    "larger the circle, the larger is the residual and hence influence of the observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making Prediction and Measuring Accuracy\n",
    "Ideally, the prediction should be made on the validation (or test) data and the accuracy of prediction\n",
    "should be evaluated.\n",
    "\n",
    "#### Predicting using the Validation Set\n",
    "The model variable has a method predict(), which takes the X parameters and returns the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pred_y variable contains the predicted value. We can compare the predicted values with the actual values\n",
    "and calculate the accuracy in the next section.\n",
    "\n",
    "#### Finding R-Squared and RMSE\n",
    "Several measures can be used for measuring the accuracy of prediction. Mean Square Error (MSE),\n",
    "Root Mean Square Error (RMSE) and Mean Absolute Percentage Error (MAPE) are some of the frequently used measures. sklearn.metrics has r2_score and mean_squared_error for measuring R-squared\n",
    "and MSE values. We need to take the square root of the MSE value to get RMSE value. \n",
    "\n",
    "Both the methods\n",
    "take predicted Y values and actual Y values to calculate the accuracy measures. Numpy module has sqrt\n",
    "method to calculate the square root of a value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, the model only explains 0.04% of the variance in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE means the average error the model makes in predicting the outcome. The smaller the value of\n",
    "RMSE, the better the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculating Prediction Intervals\n",
    "The regression equation gives us the point estimate of the outcome variable for a given value of the\n",
    "independent variable. \n",
    "\n",
    "In many applications, we would be interested in knowing the interval estimate of\n",
    "Y i for a given value of explanatory variable. wls_prediction_std() returns the prediction interval while\n",
    "making a prediction. It takes significance value (a) to calculate the interval. \n",
    "\n",
    "An a-value of 0.1 returns\n",
    "the prediction at confidence interval of 90%. The code for calculating prediction interval is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
