{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ee833aa-3f7d-4b3a-8132-a77b54655767",
   "metadata": {},
   "source": [
    "# RAG Fundamentals & Workflow\n",
    "\n",
    "- What is RAG? & Workflow\n",
    "- Why RAG matters? Overcoming LLM limitations\n",
    "- RAG Architecture\n",
    "- Hands-On RAG demo using a pre-built tool - LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66da7238-b817-49c9-a1aa-4d6212ab8fdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f8284d34-62a1-4271-9313-81b3d32c73a1",
   "metadata": {},
   "source": [
    "## What is RAG? & Workflow\n",
    "\n",
    "<img src='rag basic.png' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3a5679-f685-43f4-abeb-644e84f1912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "it retrieve relevant external data from a database on which the LLM is not trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c0be7-06e3-4ab5-a3af-f56b4dc09fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow\n",
    "\n",
    "- query = 'what is the latest advancements in renewable energy?'\n",
    "- retrieval = a retriever searches a knowledge base(documents, articles, databases) to find relevant documents\n",
    "- agumentation (context) = the retrieved documents are combine with the users query to form a better context\n",
    "- generation = LLM uses the query and retrieved context to generate a response\n",
    "\n",
    "- output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e59a5-d4e5-49c9-9fdd-fe8f2f1db273",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a34f97-bfd4-4d7e-a468-06f268178557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ada10f2e-657c-4838-9b81-b43cf18844b0",
   "metadata": {},
   "source": [
    "## Why RAG matters? Overcoming LLM limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61659c1b-1222-45d0-a81b-efb99f0f01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "limitations of LLM\n",
    "\n",
    "- limited knowledge\n",
    "- hallucination\n",
    "- context window constraints\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c85d7d26-b8dc-45ae-895d-df54e6d88c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG\n",
    "\n",
    "- integration of external data which is factual, and external context reduce hallucination\n",
    "- up to date information\n",
    "- domain specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e489f5ea-a96c-41ba-bcb5-78a7b28ea61c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae710982-31af-4cd6-aff0-59f80ba836ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2471e5a-9d15-4f94-88d4-4738e177a094",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2eae50b4-8db2-4eb6-89f9-cd7856760921",
   "metadata": {},
   "source": [
    "## RAG Architecture\n",
    "\n",
    "<img src='rag architecture.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225af739-925a-4feb-8662-def2ea7a435a",
   "metadata": {},
   "source": [
    "### Retriever Type\n",
    "\n",
    "- Sparse Retriever (BM25) - Best Matching\n",
    "keyword-based, fast but less semantic(context and intent)\n",
    "\n",
    "\n",
    "- Dense Retriever(DPR) - Dense Passage Retrieval (DPR)\n",
    "use embeddings for semantic similarity, more accurate but computaionally heavier\n",
    "\n",
    "\n",
    "### Knowledge base formats\n",
    "- text files, databases, APIs(wikipedia)\n",
    "\n",
    "### Embedding storage\n",
    "- vector databases like FAISS, pinecone, weaviate\n",
    "\n",
    "### fine-tuning\n",
    "we will only do this in domain specific tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3376f0b-b60b-4ce5-87bc-06196d8ea6e2",
   "metadata": {},
   "source": [
    "### types of RAG\n",
    "\n",
    "- Vector RAG\n",
    "vector db like FAISS, pinecone\n",
    "unstructured data like text, video, images\n",
    "\n",
    "- Graph RAG\n",
    "knowledge graph like neo4j\n",
    "structured data like relational database, csv etc\n",
    "\n",
    "- Hybrid RAG\n",
    "combine vector store + graph queries + SQL etc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f6bf2-9549-4163-9079-2a301b206eee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8f0568-d3f1-4e0a-b90e-f76824d104a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d2691a-635d-4e88-8620-de6ee75bbd04",
   "metadata": {},
   "source": [
    "## Hands-On - RAG demo using a pre-built tool - LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e509fa-1128-426d-952c-0c778abca35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "build RAG system to answer questions about a pdf (project ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658865b-7285-4eee-9325-dd6c3e18a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain\n",
    "!pip install transformers\n",
    "!pip install faiss-cpu\n",
    "!pip install sentence-transformers\n",
    "!pip install -U langchain-community\n",
    "!pip install huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b812e02-96bb-4780-a283-54df32ef7000",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. load document\n",
    "2. create embeddings\n",
    "3. setup retriever\n",
    "4. integrate LLM\n",
    "5. build RAG chain\n",
    "6. run query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92e43376-f16a-404c-b685-498b2f22116c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"projects.txt\")\n",
    "\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88bf9d38-1fdb-432a-8fd4-44d6267bfc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "# login(token=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4aded967-2bc7-441e-b13f-1536dfbdca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')\n",
    "\n",
    "vector_store = FAISS.from_documents(documents, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61ca4d85-29c9-4c4b-89f1-590bc13e112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x168de08f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5865f97b-a00b-4108-aa0c-56648a9240c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4624e5f7-d963-42c9-b355-63abdb17351a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "# llm = HuggingFacePipeline.from_model_id(model_id='gpt2', task='text-generation')\n",
    "\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "\n",
    "model_id = \"google/flan-t5-base\"  # You can also use \"tiiuae/falcon-7b-instruct\" or \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c5fb8bb-f38a-456e-89aa-ed84079fa073",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6a3ba4-3b12-425e-9e89-9418d90fe666",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = retriever.get_relevant_documents(query)\n",
    "print(f\"Number of documents retrieved: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80609e14-0ea6-4f0a-8e88-cc8ea999a801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(retriever.vectorstore.index.ntotal)  # should be > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efecb34a-df07-4403-9bbd-c4f3d16f73f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some ideas from energy sector?\"\n",
    "\n",
    "result = qa_chain.run(query)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a823e4-2c7d-420d-bae2-b7ed1de1dc50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceb0a74-e63c-49c3-a114-36d1ba38eff3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37050fa-3d98-4964-b681-b36a487fc7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb480ae5-308f-43d8-8d17-d5ce27ad8b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
